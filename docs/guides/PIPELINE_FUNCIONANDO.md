# âœ… Pipeline Completamente Funcional

## Estado: TODO FUNCIONANDO CORRECTAMENTE

Fecha de verificaciÃ³n: 2026-02-11 17:06

---

## âœ… Componentes Activos

### 1. HDFS
- âœ… NameNode: Corriendo
- âœ… DataNode: Corriendo y conectado
- âœ… Modo seguro: Desactivado
- âœ… Checkpoints: ActualizÃ¡ndose correctamente

### 2. Kafka
- âœ… Broker: Corriendo
- âœ… Topics activos:
  - `raw-data`: Recibiendo datos
  - `filtered-data`: Procesando datos limpios
  - `alerts`: Generando agregados de retrasos

### 3. Spark Streaming Jobs
- âœ… **Terminal 2:** `data_cleaning.py`
  - Procesando datos de `raw-data`
  - Escribiendo en `filtered-data`
  - Checkpoints en HDFS funcionando

- âœ… **Terminal 3:** `delay_analysis.py`
  - Procesando datos de `filtered-data`
  - Generando agregados en `alerts` (Kafka)
  - Escribiendo resultados en HDFS (`delay_aggregates`)

### 4. MongoDB
- âœ… Consumidor activo: `kafka_to_mongodb_alerts.py`
- âœ… Insertando datos en `route_delay_aggregates`
- âœ… Datos visibles: Rutas con porcentajes de retraso

---

## ğŸ“Š Datos Procesados

### Ejemplos de Datos Insertados en MongoDB:

```
âœ“ Insertado: R006 @ 2026-02-11 16:45:00+01:00 (2 vehÃ­culos, 100.0% retraso)
âœ“ Insertado: R003 @ 2026-02-11 17:00:00+01:00 (2 vehÃ­culos, 100.0% retraso)
âœ“ Insertado: R002 @ 2026-02-11 16:45:00+01:00 (4 vehÃ­culos, 100.0% retraso)
âœ“ Insertado: R003 @ 2026-02-11 16:45:00+01:00 (3 vehÃ­culos, 66.7% retraso)
```

**InterpretaciÃ³n:**
- Cada lÃ­nea representa agregados por ventana de 15 minutos
- Muestra ruta, timestamp, nÃºmero de vehÃ­culos y porcentaje de retraso
- Los datos se estÃ¡n persistiendo correctamente en MongoDB

---

## ğŸ”„ Flujo Completo Funcionando

```
1. Datos generados â†’ raw-data (Kafka)
   â†“
2. Terminal 2: data_cleaning.py
   â†’ Lee raw-data
   â†’ Limpia y valida
   â†’ Escribe filtered-data (Kafka)
   â†“
3. Terminal 3: delay_analysis.py
   â†’ Lee filtered-data
   â†’ Calcula agregados por ventana (15 min)
   â†’ Escribe alerts (Kafka) + HDFS
   â†“
4. Terminal 4: kafka_to_mongodb_alerts.py
   â†’ Lee alerts (Kafka)
   â†’ Inserta en MongoDB (route_delay_aggregates)
   âœ… DATOS PERSISTIDOS
```

---

## âœ… VerificaciÃ³n de Funcionamiento

### Comandos para Verificar:

```bash
# Ver procesos corriendo
jps | grep -E "SparkSubmit|Kafka|NameNode|DataNode"

# Ver datos en MongoDB
cd /home/hadoop/Documentos/ProyectoBigData
source venv/bin/activate
python storage/mongodb/verify_data.py

# Ver mensajes en Kafka alerts
/opt/kafka/bin/kafka-console-consumer.sh \
  --bootstrap-server localhost:9092 \
  --topic alerts \
  --from-beginning \
  --max-messages 5

# Ver datos en HDFS
hdfs dfs -ls /user/hive/warehouse/delay_aggregates/
```

---

## ğŸ¯ PrÃ³ximos Pasos (Opcionales)

1. **Generar mÃ¡s datos de prueba:**
   ```bash
   python scripts/utils/generate_sample_data.py 200
   ```

2. **Verificar estadÃ­sticas en MongoDB:**
   ```bash
   python storage/mongodb/verify_data.py
   ```

3. **Ejecutar otros consumidores MongoDB:**
   - `kafka_to_mongodb_vehicle_status.py` (estado de vehÃ­culos)
   - `import_bottlenecks.py` (despuÃ©s de anÃ¡lisis de grafos)

---

## ğŸ“ Notas

- Los scripts estÃ¡n diseÃ±ados para correr continuamente
- Los datos se procesan en tiempo real (ventanas de 15 minutos)
- Los checkpoints permiten recuperaciÃ³n ante fallos
- MongoDB persiste los datos para consultas rÃ¡pidas

---

## âœ… CONCLUSIÃ“N

**El pipeline completo estÃ¡ funcionando correctamente:**
- âœ… Ingesta (Kafka)
- âœ… Procesamiento (Spark Streaming)
- âœ… Persistencia (HDFS + MongoDB)
- âœ… Datos fluyendo end-to-end

**Â¡Pipeline operativo y listo para uso!**
