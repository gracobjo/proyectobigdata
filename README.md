# Proyecto Big Data - Plataforma de MonitorizaciÃ³n de Red de Transporte Global

## DescripciÃ³n del Proyecto

Este proyecto implementa una plataforma de Big Data capaz de monitorizar una red de transporte global, cruzando datos de sensores en tiempo real con informaciÃ³n histÃ³rica y grafos de rutas para predecir cuellos de botella y optimizar la logÃ­stica.

## Arquitectura

El proyecto sigue una **arquitectura Lambda/Kappa** 100% basada en Apache y automatiza el ciclo de vida **KDD (Knowledge Discovery in Databases)**:

1. **SelecciÃ³n**: Ingesta de datos desde mÃºltiples fuentes
2. **Preprocesamiento**: Limpieza y normalizaciÃ³n de datos
3. **TransformaciÃ³n**: Enriquecimiento y modelado de grafos
4. **MinerÃ­a**: AnÃ¡lisis en tiempo real y machine learning
5. **InterpretaciÃ³n**: VisualizaciÃ³n y reporting

## Stack TecnolÃ³gico (Apache 2026)

- **Ingesta**: Apache NiFi 2.6.0 & Apache Kafka 3.9.1 (KRaft mode)
- **Procesamiento**: Apache Spark 3.5.x (Spark SQL, Structured Streaming, GraphFrames)
- **OrquestaciÃ³n**: Apache Airflow 2.10.x
- **Almacenamiento**: 
  - HDFS 3.4.2 (datos raw y procesados)
  - MongoDB (NoSQL - Ãºltimo estado conocido de cada vehÃ­culo y agregados de retrasos)
  - Apache Hive (SQL - reporting histÃ³rico)
- **GestiÃ³n de Recursos**: YARN

## Entorno del Cluster

El proyecto estÃ¡ configurado para ejecutarse en un cluster distribuido:

- **nodo1** (equipo fÃ­sico): NameNode, ResourceManager, Kafka, MongoDB, NiFi, Airflow
- **nodo2** (VM VirtualBox): DataNode, NodeManager

Ver [docs/architecture/CLUSTER_SETUP.md](docs/architecture/CLUSTER_SETUP.md) para detalles de configuraciÃ³n del cluster.

## Estructura del Proyecto

```
ProyectoBigData/
â”œâ”€â”€ ingestion/          # Fase I: Ingesta y SelecciÃ³n
â”‚   â”œâ”€â”€ nifi/          # Configuraciones y flujos de NiFi
â”‚   â””â”€â”€ kafka/         # Scripts y configuraciones de Kafka
â”œâ”€â”€ processing/         # Fase II y III: Procesamiento
â”‚   â”œâ”€â”€ spark/
â”‚   â”‚   â”œâ”€â”€ sql/       # Scripts Spark SQL
â”‚   â”‚   â”œâ”€â”€ streaming/ # Structured Streaming
â”‚   â”‚   â””â”€â”€ graphframes/ # AnÃ¡lisis de grafos
â”‚   â””â”€â”€ scripts/       # Scripts auxiliares
â”œâ”€â”€ storage/            # Configuraciones de almacenamiento
â”‚   â”œâ”€â”€ hdfs/          # ConfiguraciÃ³n HDFS
â”‚   â”œâ”€â”€ hive/          # Schemas y scripts Hive
â”‚   â””â”€â”€ cassandra/     # DiseÃ±o lÃ³gico NoSQL (colecciones en MongoDB)
â”œâ”€â”€ orchestration/      # Fase IV: OrquestaciÃ³n
â”‚   â””â”€â”€ airflow/
â”‚       â”œâ”€â”€ dags/      # DAGs de Airflow
â”‚       â”œâ”€â”€ logs/      # Logs de ejecuciÃ³n
â”‚       â””â”€â”€ plugins/   # Plugins personalizados
â”œâ”€â”€ config/            # Archivos de configuraciÃ³n
â”‚   â””â”€â”€ cluster.properties  # ConfiguraciÃ³n centralizada del cluster
â”œâ”€â”€ data/              # Datos de ejemplo y maestros
â”‚   â”œâ”€â”€ raw/          # Datos sin procesar
â”‚   â”œâ”€â”€ processed/    # Datos procesados
â”‚   â””â”€â”€ master/       # Datos maestros
â”œâ”€â”€ docs/              # DocumentaciÃ³n
â”‚   â”œâ”€â”€ architecture/ # Diagramas de arquitectura
â”‚   â”œâ”€â”€ guides/       # GuÃ­as de uso
â”‚   â””â”€â”€ api/          # DocumentaciÃ³n de APIs
â”œâ”€â”€ tests/             # Tests unitarios e integraciÃ³n
â””â”€â”€ scripts/           # Scripts de utilidad y setup

```

## Fases del Proyecto

### Fase I: Ingesta y SelecciÃ³n (NiFi + Kafka)
- ConfiguraciÃ³n de NiFi para consumir APIs pÃºblicas (OpenWeather, FlightRadar24)
- Procesamiento de logs simulados de GPS
- PublicaciÃ³n en temas de Kafka (Datos Crudos y Datos Filtrados)
- Almacenamiento raw en HDFS para auditorÃ­a

### Fase II: Preprocesamiento y TransformaciÃ³n (Spark)
- Limpieza de datos con Spark SQL
- Enriquecimiento cruzando streaming con datos maestros de Hive
- Modelado de red de transporte con GraphFrames
- CÃ¡lculo de caminos mÃ¡s cortos y detecciÃ³n de comunidades crÃ­ticas

### Fase III: MinerÃ­a y AcciÃ³n (Streaming + ML)
- CÃ¡lculo de medias de retrasos en ventanas de 15 minutos
- Carga multicapa:
  - Hive: Datos agregados para reporting histÃ³rico
  - MongoDB: Ãšltimo estado conocido de cada vehÃ­culo y agregados recientes para consultas de baja latencia

### Fase IV: OrquestaciÃ³n (Airflow)
- DAG para re-entrenamiento mensual del modelo de grafos
- Limpieza de tablas temporales en HDFS
- CoordinaciÃ³n de workflows complejos

## Requisitos Previos

- Java 11 o superior
- Python 3.8+
- Hadoop 3.4.2 configurado en cluster (nodo1 + nodo2)
- Apache NiFi 2.6.0
- Apache Kafka 3.9.1
- Apache Spark 3.5.x
- Apache Airflow 2.10.x
- MongoDB (comunidad o Atlas)
- Apache Hive

## ðŸš€ Inicio RÃ¡pido

**Â¿Primera vez con el proyecto?** Empieza aquÃ­:

ðŸ‘‰ **[GuÃ­a de Inicio RÃ¡pido](docs/GETTING_STARTED.md)** - Paso a paso desde cero

## ConfiguraciÃ³n Inicial del Cluster

1. **Configurar /etc/hosts** en ambos nodos:
```bash
# En ambos nodos
sudo nano /etc/hosts
# AÃ±adir:
<IP_nodo1>    nodo1
<IP_nodo2>    nodo2
```

2. **Ejecutar script de configuraciÃ³n**:
```bash
./scripts/setup/configure_cluster.sh
```

3. Ver [docs/architecture/CLUSTER_SETUP.md](docs/architecture/CLUSTER_SETUP.md) para mÃ¡s detalles.

## InstalaciÃ³n

Ver [docs/guides/INSTALLATION.md](docs/guides/INSTALLATION.md) para instrucciones detalladas.

## Uso

Ver [docs/guides/USAGE.md](docs/guides/USAGE.md) para guÃ­as de uso.

## DocumentaciÃ³n

- [Arquitectura del Sistema](docs/architecture/ARCHITECTURE.md)
- [ConfiguraciÃ³n del Cluster](docs/architecture/CLUSTER_SETUP.md)
- [GuÃ­a de ConfiguraciÃ³n](docs/guides/CONFIGURATION.md)
- [InstalaciÃ³n](docs/guides/INSTALLATION.md) Â· [Uso](docs/guides/USAGE.md)
- [Airflow: instalaciÃ³n, uso y grÃ¡fico en la UI](docs/guides/AIRFLOW.md)
- [NiFi: procesadores, propiedades y conexiones](docs/guides/NIFI_FLUJOS.md)
- [VisualizaciÃ³n del grafo (Streamlit)](docs/guides/VISUALIZACION_GRAFO.md)
- [API Reference y consultas](docs/api/API.md) Â· [Swagger/OpenAPI y publicaciÃ³n de API](docs/api/SWAGGER_API.md)
- [QuÃ© mÃ¡s puede faltar (opcional)](docs/guides/QUE_FALTA.md) Â· [IA y mejora de rutas](docs/guides/IA_RUTAS.md)

## ContribuciÃ³n

Este es un proyecto acadÃ©mico siguiendo el ciclo KDD.

## Licencia

Proyecto acadÃ©mico - Uso educativo
