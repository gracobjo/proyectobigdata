# Proyecto Big Data - Plataforma de MonitorizaciÃ³n de Red de Transporte Global

## DescripciÃ³n del Proyecto

Este proyecto implementa una plataforma de Big Data capaz de monitorizar una red de transporte global, cruzando datos de sensores en tiempo real con informaciÃ³n histÃ³rica y grafos de rutas para predecir cuellos de botella y optimizar la logÃ­stica.

## Arquitectura

El proyecto sigue una **arquitectura Lambda/Kappa** 100% basada en Apache y automatiza el ciclo de vida **KDD (Knowledge Discovery in Databases)**:

1. **SelecciÃ³n**: Ingesta de datos desde mÃºltiples fuentes
2. **Preprocesamiento**: Limpieza y normalizaciÃ³n de datos
3. **TransformaciÃ³n**: Enriquecimiento y modelado de grafos
4. **MinerÃ­a**: AnÃ¡lisis en tiempo real y machine learning
5. **InterpretaciÃ³n**: VisualizaciÃ³n y reporting

## Stack TecnolÃ³gico (Apache 2026)

- **Ingesta**: Apache NiFi 2.6.0 & Apache Kafka 3.9.1 (KRaft mode)
- **Procesamiento**: Apache Spark 3.5.x (Spark SQL, Structured Streaming, GraphFrames)
- **OrquestaciÃ³n**: Apache Airflow 2.10.x
- **Almacenamiento**: 
  - HDFS 3.4.2 (datos raw y procesados)
  - MongoDB (NoSQL - Ãºltimo estado conocido de cada vehÃ­culo y agregados de retrasos)
  - Apache Hive (SQL - reporting histÃ³rico)
- **GestiÃ³n de Recursos**: YARN

## Entorno del Cluster

El proyecto estÃ¡ configurado para ejecutarse en un cluster distribuido:

- **nodo1** (equipo fÃ­sico): NameNode, ResourceManager, Kafka, MongoDB, NiFi, Airflow
- **nodo2** (VM VirtualBox): DataNode, NodeManager

Ver [docs/architecture/CLUSTER_SETUP.md](docs/architecture/CLUSTER_SETUP.md) para detalles de configuraciÃ³n del cluster.

## Estructura del Proyecto

```
ProyectoBigData/
â”œâ”€â”€ ingestion/          # Fase I: Ingesta y SelecciÃ³n
â”‚   â”œâ”€â”€ nifi/          # Configuraciones y flujos de NiFi
â”‚   â””â”€â”€ kafka/         # Scripts y configuraciones de Kafka
â”œâ”€â”€ processing/         # Fase II y III: Procesamiento
â”‚   â”œâ”€â”€ spark/
â”‚   â”‚   â”œâ”€â”€ sql/       # Scripts Spark SQL
â”‚   â”‚   â”œâ”€â”€ streaming/ # Structured Streaming
â”‚   â”‚   â””â”€â”€ graphframes/ # AnÃ¡lisis de grafos
â”‚   â””â”€â”€ scripts/       # Scripts auxiliares
â”œâ”€â”€ storage/            # Persistencia y modelos de datos
â”‚   â”œâ”€â”€ hive/          # Scripts SQL de reportes (daily_report.sql)
â”‚   â”œâ”€â”€ mongodb/       # Consumers Kafkaâ†’MongoDB, verificaciÃ³n
â”‚   â””â”€â”€ cassandra/     # DiseÃ±o lÃ³gico de colecciones MongoDB (ver README ahÃ­)
â”œâ”€â”€ orchestration/      # Fase IV: OrquestaciÃ³n
â”‚   â””â”€â”€ airflow/
â”‚       â”œâ”€â”€ dags/      # DAGs de Airflow
â”‚       â”œâ”€â”€ logs/      # Logs de ejecuciÃ³n
â”‚       â””â”€â”€ plugins/   # Plugins personalizados
â”œâ”€â”€ config/            # Archivos de configuraciÃ³n
â”‚   â””â”€â”€ cluster.properties  # ConfiguraciÃ³n centralizada del cluster
â”œâ”€â”€ data/              # Definiciones y maestros (datos crudos en HDFS/Kafka)
â”‚   â”œâ”€â”€ gps_logs/     # README; .jsonl se generan con scripts/utils
â”‚   â””â”€â”€ master/       # sample_master_data.sql para Hive/HDFS
â”œâ”€â”€ docs/              # DocumentaciÃ³n (architecture, guides, api)
â”œâ”€â”€ api/               # API REST (MongoDB)
â”œâ”€â”€ routing/           # Recomendador de rutas y modelo de retrasos
â”œâ”€â”€ viz/               # VisualizaciÃ³n del grafo
â””â”€â”€ scripts/           # Setup, run, stack (arranque/parada de la pila)
```

**Hive y carpetas â€œvacÃ­asâ€:** Los datos viven en HDFS, Kafka y MongoDB. Algunas carpetas solo tienen configs o documentaciÃ³n. Ver **docs/guides/HIVE_Y_ESTRUCTURA_PROYECTO.md**.

## Fases del Proyecto

### Fase I: Ingesta y SelecciÃ³n (NiFi + Kafka)
- ConfiguraciÃ³n de NiFi para consumir APIs pÃºblicas (OpenWeather, FlightRadar24)
- Procesamiento de logs simulados de GPS
- PublicaciÃ³n en temas de Kafka (Datos Crudos y Datos Filtrados)
- Almacenamiento raw en HDFS para auditorÃ­a

### Fase II: Preprocesamiento y TransformaciÃ³n (Spark)
- Limpieza de datos con Spark SQL
- Enriquecimiento cruzando streaming con datos maestros de Hive
- Modelado de red de transporte con GraphFrames
- CÃ¡lculo de caminos mÃ¡s cortos y detecciÃ³n de comunidades crÃ­ticas

### Fase III: MinerÃ­a y AcciÃ³n (Streaming + ML)
- CÃ¡lculo de medias de retrasos en ventanas de 15 minutos
- Carga multicapa:
  - Hive: Datos agregados para reporting histÃ³rico
  - MongoDB: Ãšltimo estado conocido de cada vehÃ­culo y agregados recientes para consultas de baja latencia

### Fase IV: OrquestaciÃ³n (Airflow)
- DAG para re-entrenamiento mensual del modelo de grafos
- Limpieza de tablas temporales en HDFS
- CoordinaciÃ³n de workflows complejos

## Requisitos Previos

- Java 11 o superior
- Python 3.8+
- Hadoop 3.4.2 configurado en cluster (nodo1 + nodo2)
- Apache NiFi 2.6.0
- Apache Kafka 3.9.1
- Apache Spark 3.5.x
- Apache Airflow 2.10.x
- MongoDB (comunidad o Atlas)
- Apache Hive

## ğŸš€ Inicio RÃ¡pido

**Â¿Primera vez con el proyecto?** Empieza aquÃ­:

ğŸ‘‰ **[GuÃ­a de Inicio RÃ¡pido](docs/GETTING_STARTED.md)** - Paso a paso desde cero

**Probar sin instalar (Colab, Jupyter, Binder)**  
Notebook listo para ejecutar en [Google Colab](https://colab.research.google.com/github/gracobjo/proyectobigdata/blob/main/notebooks/ProyectoBigData_Colab.ipynb) o [Binder](https://mybinder.org/v2/gh/gracobjo/proyectobigdata/HEAD?labpath=notebooks%2FProyectoBigData_Colab.ipynb): recomendador de rutas y opcional API con MongoDB Atlas. Ver [docs/despliegue-colab-jupyter.md](docs/despliegue-colab-jupyter.md).

## ConfiguraciÃ³n Inicial del Cluster

1. **Configurar /etc/hosts** en ambos nodos:
```bash
# En ambos nodos
sudo nano /etc/hosts
# AÃ±adir:
<IP_nodo1>    nodo1
<IP_nodo2>    nodo2
```

2. **Ejecutar script de configuraciÃ³n**:
```bash
./scripts/setup/configure_cluster.sh
```

3. Ver [docs/architecture/CLUSTER_SETUP.md](docs/architecture/CLUSTER_SETUP.md) para mÃ¡s detalles.

## InstalaciÃ³n

Ver [docs/guides/INSTALLATION.md](docs/guides/INSTALLATION.md) para instrucciones detalladas.

## Uso

Ver [docs/guides/USAGE.md](docs/guides/USAGE.md) para guÃ­as de uso.

## DocumentaciÃ³n

**Ãndice completo:** [docs/README.md](docs/README.md) â€” Ingesta, datos, storage, componentes, scripts, orquestaciÃ³n, guÃ­as y API.

- [Arquitectura del Sistema](docs/architecture/ARCHITECTURE.md) Â· [ConfiguraciÃ³n del Cluster](docs/architecture/CLUSTER_SETUP.md)
- [GuÃ­a de ConfiguraciÃ³n](docs/guides/CONFIGURATION.md) Â· [InstalaciÃ³n](docs/guides/INSTALLATION.md) Â· [Uso](docs/guides/USAGE.md)
- [Airflow](docs/guides/AIRFLOW.md) Â· [NiFi (flujos y propiedades)](docs/guides/NIFI_FLUJOS.md) Â· [Fuentes de datos](docs/guides/FUENTES_DATOS.md)
- [IoT / sensores](docs/guides/IOT_SENSORES.md) Â· [VisualizaciÃ³n del grafo](docs/guides/VISUALIZACION_GRAFO.md)
- [API Reference](docs/api/API.md) Â· [Swagger/OpenAPI](docs/api/SWAGGER_API.md) Â· [IA y rutas](docs/guides/IA_RUTAS.md)

## ContribuciÃ³n

Este es un proyecto acadÃ©mico siguiendo el ciclo KDD.

## Licencia

Proyecto acadÃ©mico - Uso educativo
